import requests
import re
import subprocess
import concurrent.futures
import os
import sys
from collections import defaultdict

def download_file(url):
    """ä¸‹è½½åŸå§‹é…ç½®æ–‡ä»¶"""
    print("æ­£åœ¨ä¸‹è½½é…ç½®æ–‡ä»¶...")
    try:
        response = requests.get(url, timeout=30)
        response.raise_for_status()
        return response.text
    except requests.RequestException as e:
        print(f"ä¸‹è½½æ–‡ä»¶å¤±è´¥: {e}")
        sys.exit(1)

def remove_first_two_lines(content):
    """åˆ é™¤å‰ä¸¤è¡Œ"""
    lines = content.split('\n')
    return '\n'.join(lines[2:])

def remove_multicast_chars(content):
    """åˆ é™¤æ‰€æœ‰-ç»„æ’­å­—ç¬¦"""
    return content.replace('-ç»„æ’­', '')

def parse_groups(content):
    """è§£æåˆ†ç»„å’Œé¢‘é“ä¿¡æ¯"""
    groups = {}
    current_group = None
    current_channels = []
    
    lines = content.split('\n')
    for line in lines:
        line = line.strip()
        if not line:
            continue
            
        if '#genre#' in line:
            # ä¿å­˜ä¸Šä¸€ä¸ªåˆ†ç»„
            if current_group and current_channels:
                groups[current_group] = current_channels
            
            # å¼€å§‹æ–°åˆ†ç»„
            current_group = line.split(',#genre#')[0]
            current_channels = []
        elif current_group and ',' in line:
            # é¢‘é“è¡Œ
            parts = line.split(',', 1)
            if len(parts) == 2:
                channel_name, channel_url = parts
                # æ¸…ç†URLä¸­çš„ç‰¹æ®Šå­—ç¬¦
                channel_url = channel_url.strip()
                current_channels.append((channel_name, channel_url))
    
    # ä¿å­˜æœ€åä¸€ä¸ªåˆ†ç»„
    if current_group and current_channels:
        groups[current_group] = current_channels
    
    return groups

def check_stream(url, timeout=5):
    """ä½¿ç”¨ffprobeæ£€æµ‹æµæ˜¯å¦æœ‰æ•ˆ"""
    try:
        result = subprocess.run(
            ["ffprobe", "-v", "error", "-show_streams", "-select_streams", "v:0", 
             "-of", "default=noprint_wrappers=1:nokey=1", "-i", url],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            timeout=timeout + 2
        )
        # æ£€æŸ¥æ˜¯å¦æœ‰è§†é¢‘æµè¾“å‡º
        return result.returncode == 0 and result.stdout
    except subprocess.TimeoutExpired:
        print(f"æ£€æµ‹è¶…æ—¶: {url}")
        return False
    except Exception as e:
        print(f"æ£€æµ‹å¤±è´¥ {url}: {e}")
        return False

def test_group_first_channel(group_name, channels):
    """æµ‹è¯•åˆ†ç»„ç¬¬ä¸€ä¸ªé¢‘é“çš„æœ‰æ•ˆæ€§"""
    if not channels:
        return group_name, False
    
    first_channel_name, first_channel_url = channels[0]
    print(f"æµ‹è¯•åˆ†ç»„ '{group_name}' çš„ç¬¬ä¸€ä¸ªé¢‘é“: {first_channel_name}")
    
    try:
        is_valid = check_stream(first_channel_url)
        if is_valid:
            print(f"âœ“ åˆ†ç»„ '{group_name}' æœ‰æ•ˆ")
        else:
            print(f"âœ— åˆ†ç»„ '{group_name}' æ— æ•ˆ")
        return group_name, is_valid
    except Exception as e:
        print(f"æµ‹è¯•åˆ†ç»„ '{group_name}' æ—¶å‡ºé”™: {e}")
        return group_name, False

def test_groups(groups, max_workers=5):
    """æµ‹è¯•æ‰€æœ‰åˆ†ç»„çš„æœ‰æ•ˆæ€§"""
    print(f"ğŸš€ å¯åŠ¨å¤šçº¿ç¨‹æ£€æµ‹ï¼ˆå…± {len(groups)} ä¸ªåˆ†ç»„ï¼‰...")
    valid_groups = {}
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        # æäº¤æ‰€æœ‰æ£€æµ‹ä»»åŠ¡
        future_to_group = {
            executor.submit(test_group_first_channel, group_name, channels): group_name 
            for group_name, channels in groups.items()
        }
        
        # æ”¶é›†ç»“æœ
        for future in concurrent.futures.as_completed(future_to_group):
            group_name, is_valid = future.result()
            if is_valid:
                valid_groups[group_name] = groups[group_name]
    
    print(f"âœ… æ£€æµ‹å®Œæˆï¼Œæœ‰æ•ˆåˆ†ç»„å…± {len(valid_groups)} ä¸ª")
    return valid_groups

def process_valid_channels(valid_groups):
    """å¤„ç†æœ‰æ•ˆé¢‘é“ï¼Œç”Ÿæˆå¹³è¡¨æ ¼å¼"""
    flat_channels = []
    seen_channels = set()  # ç”¨äºå»é‡
    
    for group_name, channels in valid_groups.items():
        for channel_name, channel_url in channels:
            # åˆ›å»ºå”¯ä¸€æ ‡è¯†è¿›è¡Œå»é‡
            channel_key = f"{channel_name}|{channel_url}"
            if channel_key not in seen_channels:
                seen_channels.add(channel_key)
                # åœ¨URLåæ·»åŠ $è¿è¥å•†åˆ†ç»„
                processed_url = f"{channel_url}${group_name}"
                flat_channels.append((channel_name, processed_url, group_name))
    
    return flat_channels

def recategorize_channels(channels):
    """æŒ‰ç…§è‡ªå®šä¹‰è§„åˆ™é‡æ–°åˆ†ç±»é¢‘é“"""
    categories = {
        "å¤®è§†": [],
        "å«è§†": [],
        "åœ°æ–¹å°": [],
        "ç”µå½±": [],
        "ä½“è‚²": [],
        "å°‘å„¿": [],
        "å…¶ä»–": []
    }
    
    # åˆ†ç±»è§„åˆ™
    for channel_name, channel_url, group_name in channels:
        channel_name_lower = channel_name.lower()
        
        if any(keyword in channel_name for keyword in ['CCTV', 'å¤®è§†', 'ä¸­å¤®']):
            categories["å¤®è§†"].append((channel_name, channel_url))
        elif any(keyword in channel_name_lower for keyword in ['å«è§†', 'tv']):
            categories["å«è§†"].append((channel_name, channel_url))
        elif any(keyword in channel_name for keyword in [
            'åŒ—äº¬', 'ä¸Šæµ·', 'å¹¿ä¸œ', 'æ¹–å—', 'æµ™æ±Ÿ', 'æ±Ÿè‹', 'å››å·', 'é‡åº†', 
            'å¤©æ´¥', 'æ²³åŒ—', 'å±±è¥¿', 'è¾½å®', 'å‰æ—', 'é»‘é¾™æ±Ÿ', 'å®‰å¾½', 
            'ç¦å»º', 'æ±Ÿè¥¿', 'å±±ä¸œ', 'æ²³å—', 'æ¹–åŒ—', 'å¹¿è¥¿', 'æµ·å—', 'è´µå·',
            'äº‘å—', 'é™•è¥¿', 'ç”˜è‚ƒ', 'é’æµ·', 'å°æ¹¾', 'é¦™æ¸¯', 'æ¾³é—¨'
        ]):
            categories["åœ°æ–¹å°"].append((channel_name, channel_url))
        elif any(keyword in channel_name_lower for keyword in ['ç”µå½±', 'å½±é™¢', 'å‰§åœº']):
            categories["ç”µå½±"].append((channel_name, channel_url))
        elif any(keyword in channel_name_lower for keyword in ['ä½“è‚²', 'è¶³çƒ', 'ç¯®çƒ', 'èµ›äº‹']):
            categories["ä½“è‚²"].append((channel_name, channel_url))
        elif any(keyword in channel_name_lower for keyword in ['å°‘å„¿', 'å¡é€š', 'åŠ¨ç”»', 'åŠ¨æ¼«']):
            categories["å°‘å„¿"].append((channel_name, channel_url))
        else:
            categories["å…¶ä»–"].append((channel_name, channel_url))
    
    return categories

def save_categorized_channels(categories, output_file):
    """ä¿å­˜é‡æ–°åˆ†ç±»åçš„é¢‘é“åˆ°æ–‡ä»¶"""
    with open(output_file, 'w', encoding='utf-8') as f:
        for category, channels in categories.items():
            if channels:  # åªè¾“å‡ºæœ‰é¢‘é“çš„åˆ†ç±»
                f.write(f"{category},#genre#\n")
                for channel_name, channel_url in channels:
                    f.write(f"{channel_name},{channel_url}\n")
                f.write("\n")
    
    print(f"å¤„ç†å®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ°: {output_file}")

def save_flat_channels(channels, output_file):
    """ä¿å­˜å¹³è¡¨æ ¼å¼çš„é¢‘é“åˆ—è¡¨"""
    with open(output_file, 'w', encoding='utf-8') as f:
        for channel_name, channel_url, group_name in channels:
            f.write(f"{channel_name},{channel_url}\n")
    
    print(f"å¹³è¡¨æ ¼å¼å·²ä¿å­˜åˆ°: {output_file}")

def check_ffmpeg_availability():
    """æ£€æŸ¥ffmpegæ˜¯å¦å¯ç”¨"""
    try:
        result = subprocess.run(['ffprobe', '-version'], 
                              capture_output=True, text=True, timeout=10)
        if result.returncode == 0:
            print("âœ… ffprobe å¯ç”¨")
            return True
        else:
            print("âŒ ffprobe ä¸å¯ç”¨")
            return False
    except Exception as e:
        print(f"âŒ æ£€æŸ¥ffprobeæ—¶å‡ºé”™: {e}")
        return False

def main():
    # é…ç½®æ–‡ä»¶URL
    url = "https://raw.githubusercontent.com/q1017673817/iptvz/main/zubo_all.txt"
    
    try:
        # æ£€æŸ¥ffmpegæ˜¯å¦å¯ç”¨
        if not check_ffmpeg_availability():
            print("è¯·ç¡®ä¿å·²å®‰è£…ffmpeg")
            sys.exit(1)
        
        # 1. ä¸‹è½½æ–‡ä»¶
        content = download_file(url)
        
        # 2. åˆ é™¤å‰ä¸¤è¡Œ
        content = remove_first_two_lines(content)
        
        # 3. åˆ é™¤-ç»„æ’­å­—ç¬¦
        content = remove_multicast_chars(content)
        
        # 4. è§£æåŸå§‹åˆ†ç»„
        original_groups = parse_groups(content)
        print(f"æ‰¾åˆ° {len(original_groups)} ä¸ªåŸå§‹åˆ†ç»„")
        
        # æ˜¾ç¤ºå‰å‡ ä¸ªåˆ†ç»„ä½œä¸ºç¤ºä¾‹
        sample_groups = list(original_groups.keys())[:5]
        print(f"ç¤ºä¾‹åˆ†ç»„: {sample_groups}")
        
        # 5. æµ‹è¯•åˆ†ç»„æœ‰æ•ˆæ€§ï¼ˆå‡å°‘å¹¶å‘æ•°ä»¥é¿å…èµ„æºé™åˆ¶ï¼‰
        valid_groups = test_groups(original_groups, max_workers=3)
        
        # 6. å¤„ç†æœ‰æ•ˆé¢‘é“ï¼Œç”Ÿæˆå¹³è¡¨
        flat_channels = process_valid_channels(valid_groups)
        print(f"æœ‰æ•ˆé¢‘é“æ•°é‡: {len(flat_channels)}")
        
        # 7. ä¿å­˜å¹³è¡¨æ ¼å¼
        flat_output_file = "flat_iptv_list.txt"
        save_flat_channels(flat_channels, flat_output_file)
        
        # 8. é‡æ–°åˆ†ç±»
        categories = recategorize_channels(flat_channels)
        
        # 9. ä¿å­˜åˆ†ç±»æ ¼å¼
        categorized_output_file = "categorized_iptv_list.txt"
        save_categorized_channels(categories, categorized_output_file)
        
        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        total_channels = sum(len(channels) for channels in categories.values())
        print(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        print(f"æ€»é¢‘é“æ•°: {total_channels}")
        for category, channels in categories.items():
            if channels:
                print(f"{category}: {len(channels)} ä¸ªé¢‘é“")
                
    except Exception as e:
        print(f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()